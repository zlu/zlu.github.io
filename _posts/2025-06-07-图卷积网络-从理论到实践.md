---
layout: post
title: 图卷积网络：从理论到实践
date: 2025-06-07 20:43 +0800
tags:
  - python
  - 人工智能
  - 机器学习
  - 图卷积网络
  - GCN
description: 图卷积网络：从理论到实践
---

图卷积网络（Graph Convolutional Networks, GCNs）彻底改变了基于图的机器学习领域，使得深度学习能够应用于非欧几里得结构，如社交网络、引文网络和分子结构。本文将解释GCN的直观理解、数学原理，并提供代码片段帮助您理解和实现基础的GCN。传统的CNN在图像或文本等网格状数据上表现良好，但对于节点连接各异且没有固定空间局部性的任意图结构却难以处理。GCN通过在图结构上执行卷积操作克服了这一限制。

## 图表示法基础

定义图G = (V, E)，其中：
- $V$：节点集合
- $E$：边集合
- $A \in \mathbb{R}^{N \times N}$：邻接矩阵
- $X \in \mathbb{R}^{N \times F}$：节点特征矩阵

其中，$N$是节点数量，$F$是每个节点的输入特征数量。

### 邻接矩阵
邻接矩阵是表示图中节点之间连接（边）的一种方式。
- 对于具有$N$个节点的图，$A$是一个$N \times N$的矩阵。
- 如果节点$i$和节点$j$之间有边，则$A_{ij} = 1$（如果带权重，则为边的权重）；否则$A_{ij} = 0$。
- 在无向图中，$A$是对称的（$A_{ij} = A_{ji}$）。
- 例如，一个3节点图，其中节点0连接到节点1和2：
  $$
  A = \begin{bmatrix}
  0 & 1 & 1 \\
  1 & 0 & 0 \\
  1 & 0 & 0
  \end{bmatrix}
  $$

![邻接矩阵](/assets/images/uploads/adjacency-matrix.png)

### 节点特征矩阵

节点特征矩阵存储图中每个节点的特征（属性）。
- $N$是节点数量，$F$是每个节点的特征数量。
- 每一行$X_i$是节点$i$的特征向量。
- 例如，如果每个节点有3个特征（比如年龄、收入和组别），共有4个节点：
  $$
  X = \begin{bmatrix}
  23 & 50000 & 1 \\
  35 & 60000 & 2 \\
  29 & 52000 & 1 \\
  41 & 58000 & 3
  \end{bmatrix}
  $$
- 这些特征是GCN用来学习的输入。

两者共同构成了图卷积网络的基本输入：
- 邻接矩阵$A$描述了节点如何连接。
- 节点特征矩阵$X$描述了每个节点的特征。

### GCN层公式（Kipf & Welling, 2016）

GCN层的核心公式如下：

$$H^{(l+1)} = \sigma(\tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(l)} W^{(l)})$$

这个公式包含了很多信息，我们将在下面详细解析：

#### 输入：

- $H^{(l)}$：上一层的节点特征（对于第一层，$H^{(0)} = X$，即输入特征）
- $\tilde{A} = A + I$：添加了自环的邻接矩阵（$I$是单位矩阵）
- $\tilde{D}$：$\tilde{A}$的对角度矩阵（包含每个节点的连接数，包括自环）
- $W^{(l)}$：第$l$层的可训练权重矩阵
- $\sigma$：非线性激活函数（如ReLU）

#### 关键操作：

- 消息传递：
  - $\tilde{A}H^{(l)}$：每个节点聚合其邻居的特征向量
  - 添加自环（$\tilde{A} = A + I$）确保节点在聚合时包含自身特征
- 归一化：防止特征尺度在层间变化过大，通过节点度进行归一化有助于训练稳定性
  - $\tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}$：这步称为对称归一化或重归一化技巧
  - 如果没有归一化，具有许多连接（高度数）的节点在聚合后会有更大的特征值，这可能导致数值不稳定和训练困难

### 在Cora数据集上实现GCN节点分类

Cora数据集是一个引文网络，其中节点代表学术论文，边代表引用关系。每篇论文都有一组特征（如作者、标题、摘要）和一个标签（如论文主题）。总共有2,780篇论文（节点）和5,429条引用（边）。每篇论文由一个二进制词向量表示，表示1,433个唯一词典单词的存在（1）或不存在（0）。论文被分为7个类别（如神经网络、概率方法等）。目标是根据每篇论文的特征和引用关系预测其类别。

#### 模型架构

GCN模型有2层：

```python
class GCN(torch.nn.Module):
    def __init__(self):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(dataset.num_node_features, 16)  # 输入到隐藏层
        self.conv2 = GCNConv(16, dataset.num_classes)       # 隐藏层到输出
```

第一层GCN将输入特征（1,433维）降维到16维。第二层GCN将16维降维到7维（类别数）。

#### 前向传播函数

```python
def forward(self):
    x, edge_index = data.x, data.edge_index
    x = self.conv1(x, edge_index)  # 第一层GCN
    x = F.relu(x)                  # 非线性激活
    x = F.dropout(x, training=self.training)  # 可选dropout
    x = self.conv2(x, edge_index)  # 第二层GCN
    return F.log_softmax(x, dim=1)  # 每个类别的对数概率
```

`x = self.conv1(x, edge_index)` 做了几件事：它向图中添加自环，计算归一化邻接矩阵$\tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2}$，与输入特征和权重$H^{(l)} W^{(l)}$相乘，并应用归一化和聚合。基本上，所有复杂的数学运算都由GCNConv层处理了。

#### 训练过程

```python
model = GCN()
data = dataset[0]  # 获取第一个图对象
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)

model.train()
for epoch in range(200):
    optimizer.zero_grad()
    out = model(data)
    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
```

我们使用带权重衰减的Adam优化器。Adam是一种自适应学习率优化算法，它结合了AdaGrad和RMSProp的优点。它维护每个参数的学习率，并使用梯度的移动平均和梯度平方的移动平均。由于稀疏梯度在GNN中很常见，使用Adam是合理的。

#### 模型评估

```python
model.eval()
pred = model().argmax(dim=1)  # 获取预测类别
correct = pred[data.test_mask] == data.y[data.test_mask]
accuracy = int(correct.sum()) / int(data.test_mask.sum())
```

完整代码如下：

```python
import torch
import torch.nn.functional as F
from torch_geometric.datasets import Planetoid
from torch_geometric.nn import GCNConv

# 加载数据
dataset = Planetoid(root='/tmp/Cora', name='Cora')
data = dataset[0]

# 定义GCN模型
class GCN(torch.nn.Module):
    def __init__(self):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(dataset.num_node_features, 16)
        self.conv2 = GCNConv(16, dataset.num_classes)

    def forward(self):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)

# 训练循环
model = GCN()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)

for epoch in range(200):
    model.train()
    optimizer.zero_grad()
    out = model()
    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
    if epoch % 20 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')

# 评估
model.eval()
pred = model().argmax(dim=1)
correct = pred[data.test_mask] == data.y[data.test_mask]
accuracy = int(correct.sum()) / int(data.test_mask.sum())
print(f'测试准确率: {accuracy:.4f}')
```

运行结果：

```
Epoch 0, Loss: 1.9515
Epoch 20, Loss: 0.1116
Epoch 40, Loss: 0.0147
Epoch 60, Loss: 0.0142
Epoch 80, Loss: 0.0166
Epoch 100, Loss: 0.0155
Epoch 120, Loss: 0.0137
Epoch 140, Loss: 0.0124
Epoch 160, Loss: 0.0114
Epoch 180, Loss: 0.0107
测试准确率: 0.8100
```

我们可以看到，模型在只看到少量标记节点的情况下就能达到相当不错的准确率（81%）。这展示了图结构与节点特征结合的力量。在下一篇博客中，我们将介绍EvolveGCN，这是一个可以处理动态图数据的动态GCN模型。
